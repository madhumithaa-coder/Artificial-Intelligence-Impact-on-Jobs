# -*- coding: utf-8 -*-
"""AIimpact.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_T3XC8zO_70h_hXIEk9fWo6_ImnOZUH2
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

data = pd.read_csv("AI_Impact_on_Jobs_2030.csv")
print(data.head())

print(data.isnull().sum())

data.duplicated().sum()

num_cols=data.select_dtypes(include=['int64','float64']).columns
print(num_cols)
cat_cols=data.select_dtypes(include=['object']).columns
print(cat_cols)
num_imputer=SimpleImputer(strategy='mean')
cat_imputer=SimpleImputer(strategy='most_frequent')
data[num_cols]==num_imputer.fit_transform(data[num_cols])
data[cat_cols]==cat_imputer.fit_transform(data[cat_cols])

def remove_outliers(data, column):
  Q1=data[column].qunatile(0.25)
  Q3=data[column].qunatile(0.75)
  IQR=Q3-Q1
  lower=Q1-1.5*IQR
  upper=Q3+1.5*IQR
  return data[(data[column])>=lower&(data[column])<=upper]
  data=remove_outliers(data,"Fare")

label_cols=['Risk_Category']
le=LabelEncoder()
for col in label_cols:
  data[col]=le.fit_transform(data[col])

data=pd.get_dummies(data,columns=[col for col in cat_cols if col not in label_cols])

scaler=StandardScaler()
data[num_cols]=scaler.fit_transform(data[num_cols])

corr = data.corr()
print(corr['Risk_Category'].sort_values(ascending=False))

median_RC=data['Risk_Category'].median()
RC_cat=data['Risk_Category'].apply(lambda x:'high' if x >= median_RC else 'low')
RC_counts=RC_cat.value_counts()
plt.pie(RC_counts,labels=RC_counts.index.tolist(),autopct='%.f%%',shadow=True)
plt.title("Risk status")
plt.show()

X = data.drop('Risk_Category', axis=1)
y =  data['Risk_Category']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size = 0.3, random_state = 4)

print ('Train set:', X_train.shape, y_train.shape)
print ('Test set:', X_test.shape, y_test.shape)

#1 Logistic Regression
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", model.score(X_test, y_test))

#2 K-Nearest Neighbors
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=5)
model.fit (X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", model.score(X_test, y_test))

#3 Decision Tree
from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", model.score(X_test, y_test))

#4 Random Forest
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", model.score(X_test, y_test))

#5. Support Vector Machine
from sklearn.svm import SVC
model = SVC()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", model.score(X_test, y_test))

#6. Gradient Boosting
from sklearn.ensemble import GradientBoostingClassifier
model = GradientBoostingClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", model.score(X_test, y_test))

#7. Naive Bayes
from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", model.score(X_test, y_test))